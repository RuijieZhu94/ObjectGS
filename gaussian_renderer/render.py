#
# Copyright (C) 2023, Inria
# GRAPHDECO research group, https://team.inria.fr/graphdeco
# All rights reserved.
#
# This software is free for non-commercial, research and evaluation use 
# under the terms of the LICENSE.md file.
#
# For inquiries contact  george.drettakis@inria.fr
#
import torch
import math
import gsplat
from gsplat.cuda._wrapper import fully_fused_projection, fully_fused_projection_2dgs
# from gsplat.cuda._torch_impl import _fully_fused_projection as fully_fused_projection
# from gsplat.cuda._torch_impl_2dgs import _fully_fused_projection_2dgs as fully_fused_projection_2dgs

def render(viewpoint_camera, pc, pipe, bg_color, visible_mask=None, training=True, object_mask=None):
    """
    Render the scene. 
    
    Background tensor (bg_color) must be on GPU!
    """
    if pc.explicit_gs:
        xyz, color, opacity, scaling, rot, sh_degree, selection_mask = pc.generate_explicit_gaussians(visible_mask)
    else:
        xyz, offset, color, opacity, scaling, rot, sh_degree, selection_mask, semantics = pc.generate_neural_gaussians(viewpoint_camera, visible_mask, training)
        # xyz, offset, color, opacity, scaling, rot, sh_degree, selection_mask, semantics = pc.generate_neural_gaussians(viewpoint_camera, visible_mask & ~object_mask, training)
        # xyz_1, offset_1, color_1, opacity_1, scaling_1, rot_1, sh_degree_1, selection_mask_1, semantics_1 = pc.generate_neural_gaussians(viewpoint_camera, visible_mask & object_mask, training)
        # xyz = torch.cat((xyz, xyz_1), dim=0)
        # offset = torch.cat((offset, offset_1), dim=0)
        # color = torch.cat((color, 1 - color_1), dim=0)
        # opacity = torch.cat((opacity, opacity_1), dim=0)
        # scaling = torch.cat((scaling, scaling_1), dim=0)
        # rot = torch.cat((rot, rot_1), dim=0)
        # # sh_degree = torch.cat((sh_degree, sh_degree_1), dim=0)
        # selection_mask = torch.cat((selection_mask, selection_mask_1), dim=0)
        # semantics = torch.cat((semantics, semantics_1), dim=0)
    # Set up rasterization configuration
    K = torch.tensor([
            [viewpoint_camera.fx, 0, viewpoint_camera.cx],
            [0, viewpoint_camera.fy, viewpoint_camera.cy],
            [0, 0, 1],
        ],dtype=torch.float32, device="cuda")
    viewmat = viewpoint_camera.world_view_transform.transpose(0, 1) # [4, 4]
    
    if pc.gs_attr == "3D":
        render_colors, render_alphas, render_semantics, info = gsplat.rasterization(
            means=xyz,  # [N, 3]
            quats=rot,  # [N, 4]
            scales=scaling,  # [N, 3]
            opacities=opacity.squeeze(-1),  # [N,]
            colors=color,
            viewmats=viewmat[None],  # [1, 4, 4]
            Ks=K[None],  # [1, 3, 3]
            width=int(viewpoint_camera.image_width),
            height=int(viewpoint_camera.image_height),            
            backgrounds=bg_color[None],
            packed=False,
            sh_degree=sh_degree,
            render_mode=pc.render_mode,
            features=semantics.detach()
        )
    elif pc.gs_attr == "2D":
        (render_colors, 
        render_alphas,
        render_normals,
        render_normals_from_depth,
        render_distort,
        render_median,
        render_semantics,
        info) = \
        gsplat.rasterization_2dgs(
            means=xyz,  # [N, 3]
            quats=rot,  # [N, 4]
            scales=scaling,  # [N, 3]
            opacities=opacity.squeeze(-1),  # [N,]
            colors=color,
            viewmats=viewmat[None],  # [1, 4, 4]
            Ks=K[None],  # [1, 3, 3]
            width=int(viewpoint_camera.image_width),
            height=int(viewpoint_camera.image_height),            
            backgrounds=bg_color[None] if pc.render_mode not in ["RGB+D", "RGB+ED"] \
                else torch.cat((bg_color[None], torch.zeros((1, 1), device="cuda")), dim=-1),
            packed=False,
            sh_degree=sh_degree,
            render_mode=pc.render_mode,
            features=semantics.detach()
        )
    else:
        raise ValueError(f"Unknown gs_attr: {pc.gs_attr}")

    # [1, H, W, 3] -> [3, H, W]
    if render_colors.shape[-1] == 4:
        colors, depths = render_colors[..., 0:3], render_colors[..., 3:4]
        depth = depths[0].permute(2, 0, 1)
    else:
        colors = render_colors
        depth = None

    rendered_image = colors[0].permute(2, 0, 1)
    radii = info["radii"].squeeze(0) # [N,]
    try:
        info["means2d"].retain_grad() # [1, N, 2]
    except:
        pass

    render_alphas = render_alphas[0].permute(2, 0, 1)

    # Those Gaussians that were frustum culled or had a radius of 0 were not visible.
    return_dict = {
        "render": rendered_image,
        "scaling": scaling,
        "viewspace_points": info["means2d"],
        "visibility_filter" : radii > 0,
        "visible_mask": visible_mask,
        "selection_mask": selection_mask,
        "opacity": opacity,
        "render_depth": depth,
        "radii": radii,
        "render_alphas": render_alphas,
        "render_semantics": render_semantics,
    }
    
    if pc.gs_attr == "2D":
        return_dict.update({
            "render_normals": render_normals,
            "render_normals_from_depth": render_normals_from_depth,
            "render_distort": render_distort,
        })

    return return_dict

def prefilter_voxel(viewpoint_camera, pc):
    """
    Render the scene. 
    
    Background tensor (bg_color) must be on GPU!
    """
    means = pc.get_anchor[pc._anchor_mask]
    scales = pc.get_scaling[pc._anchor_mask][:, :3]
    quats = pc.get_rotation[pc._anchor_mask]
    
    # Set up rasterization configuration
    Ks = torch.tensor([
            [viewpoint_camera.fx, 0, viewpoint_camera.cx],
            [0, viewpoint_camera.fy, viewpoint_camera.cy],
            [0, 0, 1],
        ],dtype=torch.float32, device="cuda")[None]
    viewmats = viewpoint_camera.world_view_transform.transpose(0, 1)[None]

    N = means.shape[0]
    C = viewmats.shape[0]
    device = means.device
    assert means.shape == (N, 3), means.shape
    assert quats.shape == (N, 4), quats.shape
    assert scales.shape == (N, 3), scales.shape
    assert viewmats.shape == (C, 4, 4), viewmats.shape
    assert Ks.shape == (C, 3, 3), Ks.shape

    # Project Gaussians to 2D. Directly pass in {quats, scales} is faster than precomputing covars.
    if pc.gs_attr == "3D":
        proj_results = fully_fused_projection(
            means,
            None,  # covars,
            quats,
            scales,
            viewmats,
            Ks,
            int(viewpoint_camera.image_width),
            int(viewpoint_camera.image_height),
            eps2d=0.3,
            packed=False,
            near_plane=0.01,
            far_plane=1e10,
            radius_clip=0.0,
            sparse_grad=False,
            calc_compensations=False,
        )
    elif pc.gs_attr == "2D":
        # densifications = (
        #     torch.zeros((C, N, 2), dtype=means.dtype, device="cuda")
        # )
        # Project Gaussians to 2D. Directly pass in {quats, scales} is faster than precomputing covars.
        proj_results = fully_fused_projection_2dgs(
            means,
            quats,
            scales,
            viewmats,
            Ks,
            int(viewpoint_camera.image_width),
            int(viewpoint_camera.image_height),
            eps2d=0.3,
            packed=False,
            near_plane=0.01,
            far_plane=1e10,
            radius_clip=0.0,
            sparse_grad=False,
        )

        # torch implementation
        # proj_results = fully_fused_projection_2dgs(
        #     means,
        #     quats,
        #     scales,
        #     viewmats,
        #     Ks,
        #     int(viewpoint_camera.image_width),
        #     int(viewpoint_camera.image_height),
        #     near_plane=0.01,
        #     far_plane=1e10,
        #     eps=0.3,
        # )
    else:
        raise ValueError(f"Unknown gs_attr: {pc.gs_attr}")
    
    # The results are with shape [C, N, ...]. Only the elements with radii > 0 are valid.
    radii, means2d, depths, conics, compensations = proj_results
    # radii, means2d, depths, M, normals = proj_results # torch impl
    camera_ids, gaussian_ids = None, None
    
    visible_mask = pc._anchor_mask.clone()
    visible_mask[pc._anchor_mask] = radii.squeeze(0) > 0

    return visible_mask